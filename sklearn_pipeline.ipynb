{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import dython as dy\n",
    "import plotly.express as px\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset.csv')\n",
    "# Setting id as index\n",
    "df.set_index('id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df.values, df.fertilizer_usage.values):\n",
    "    train_set = df.iloc[train_index]\n",
    "    test_set = df.iloc[test_index]\n",
    "\n",
    "X_train = train_set.drop(columns='yield')\n",
    "y_train = train_set['yield']\n",
    "X_test = test_set.drop(columns='yield')\n",
    "y_test = test_set['yield']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Custom Transformer that extracts columns passed as argument to its constructor\n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor\n",
    "    def __init__( self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "\n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[self.feature_names]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# Will handle water, uv, area, pesticides- fill missing values and scale\n",
    "\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor\n",
    "    def __init__( self):\n",
    "        pass\n",
    "\n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "\n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones\n",
    "    def transform(self, X, y = None):\n",
    "\n",
    "        for col in X.columns:\n",
    "            # Adjusting outliers with their percentile values\n",
    "            low = X[col].quantile(0.01)\n",
    "            high = X[col].quantile(0.99)\n",
    "\n",
    "            X[col] = np.where(X[col] < low, low,X[col])\n",
    "            X[col] = np.where(X[col] > high, high,X[col])\n",
    "\n",
    "            # # Filling the Missing Values\n",
    "            # X[col] = X.groupby('region')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "        self.num_columns = X.columns\n",
    "        #returns a numpy array\n",
    "        return X.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Now categorical variables\n",
    "\n",
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "    #Class constructor method that takes in a list of values as its argument\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "\n",
    "    #Transformer method we wrote for this transformer\n",
    "    def transform(self, X , y = None ):\n",
    "        #Depending on constructor argument break dates column into specified units\n",
    "        #using the helper functions written above\n",
    "        X = pd.get_dummies(X, columns=['region'], dtype=np.int64)\n",
    "\n",
    "        # Splitting the entries so that it can be ingested to binarizer\n",
    "        X['categories'] = X['categories'].transform(lambda x: x.split(','))\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        cats = pd.DataFrame(mlb.fit_transform(X['categories']),columns=mlb.classes_, index=X.index)\n",
    "\n",
    "        # Renaming the column value\n",
    "        cats.columns = 'pesticide_' + cats.columns.values\n",
    "        X = pd.concat([X.drop(columns='categories'), cats], axis=1)\n",
    "        self.cat_columns = X.columns\n",
    "        #returns numpy array\n",
    "        return X.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# Numerical features to pass down the numerical pipeline\n",
    "numerical_features = ['water', 'uv', 'area', 'pesticides']\n",
    "\n",
    "# Categorical features to pass donw the categorical pipeline\n",
    "categorical_features = ['fertilizer_usage', 'region', 'categories']\n",
    "\n",
    "#Defining the steps in the numerical pipeline\n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(numerical_features) ),\n",
    "\n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median') ),\n",
    "\n",
    "                                  ( 'std_scaler', RobustScaler() ) ] )\n",
    "\n",
    "\n",
    "#Defining the steps in the categorical pipeline\n",
    "categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ),\n",
    "\n",
    "                                  ( 'cat_transformer', CategoricalTransformer() )] )\n",
    "\n",
    "\n",
    "#Combining numerical and categorical pipeline into one full big pipeline horizontally\n",
    "#using FeatureUnion\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', categorical_pipeline ),\n",
    "\n",
    "                                                  ( 'numerical_pipeline', numerical_pipeline ) ] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing pipeline is ready for action\n",
    "\n",
    "Let us test it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "FeatureUnion(transformer_list=[('categorical_pipeline',\n                                Pipeline(steps=[('cat_selector',\n                                                 FeatureSelector(feature_names=['fertilizer_usage',\n                                                                                'region',\n                                                                                'categories'])),\n                                                ('cat_transformer',\n                                                 CategoricalTransformer())])),\n                               ('numerical_pipeline',\n                                Pipeline(steps=[('num_selector',\n                                                 FeatureSelector(feature_names=['water',\n                                                                                'uv',\n                                                                                'area',\n                                                                                'pesticides'])),\n                                                ('num_transformer',\n                                                 NumericalTransformer()),\n                                                ('imputer',\n                                                 SimpleImputer(strategy='median')),\n                                                ('std_scaler',\n                                                 RobustScaler())]))])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can add Models to the pipeline with a new pipeline\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', full_pipeline),\n",
    "                        ('model', XGBRegressor())])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 FeatureUnion(transformer_list=[('categorical_pipeline',\n                                                 Pipeline(steps=[('cat_selector',\n                                                                  FeatureSelector(feature_names=['fertilizer_usage',\n                                                                                                 'region',\n                                                                                                 'categories'])),\n                                                                 ('cat_transformer',\n                                                                  CategoricalTransformer())])),\n                                                ('numerical_pipeline',\n                                                 Pipeline(steps=[('num_selector',\n                                                                  FeatureSelector(feature_names=['water',\n                                                                                                 'uv',\n                                                                                                 'area',\n                                                                                                 'pe...\n                              colsample_bytree=1, gamma=0, gpu_id=-1,\n                              importance_type='gain',\n                              interaction_constraints='',\n                              learning_rate=0.300000012, max_delta_step=0,\n                              max_depth=6, min_child_weight=1, missing=nan,\n                              monotone_constraints='()', n_estimators=100,\n                              n_jobs=6, num_parallel_tree=1, random_state=0,\n                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n                              subsample=1, tree_method='exact',\n                              validate_parameters=1, verbosity=None))])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 63.554523 ,  22.413559 ,  74.66881  ,  96.53767  ,  53.915504 ,\n        52.493343 ,  68.34212  ,  60.214985 ,  89.76018  ,  77.481964 ,\n        29.804348 ,  76.86588  ,  85.59925  ,  84.90035  ,  42.402657 ,\n        93.85431  , 110.07837  ,  48.48818  ,  74.92908  , 118.890564 ,\n        55.254864 , 108.16543  , 104.95489  ,  80.335075 ,  55.16112  ,\n        35.760834 ,  27.217163 ,  80.71355  ,  59.035423 ,  47.60036  ,\n        79.65083  ,  49.32962  ,  39.54636  ,  99.02942  ,  65.260994 ,\n        64.70298  ,  57.065    ,  46.63255  ,  49.688797 ,  70.078514 ,\n        34.653324 ,  32.015278 ,  64.4864   ,  84.209274 ,  46.6324   ,\n        69.81306  ,  69.80854  ,  51.609295 ,  28.911932 ,  68.906334 ,\n        41.01254  ,  76.796425 ,  64.273994 ,  29.861624 ,  33.995064 ,\n        56.900997 ,  58.35324  ,  97.51384  ,  49.98211  ,  42.77085  ,\n        44.470886 ,  54.691727 ,  74.83789  ,  67.59571  ,  35.09203  ,\n        41.10578  , 108.75281  ,  24.702753 ,  44.551483 ,  22.739065 ,\n        57.347538 ,  29.657713 ,  30.324465 , 112.35699  ,  85.41397  ,\n        55.32738  ,  64.302444 ,  29.770908 ,  73.85351  ,  42.197636 ,\n        53.753036 ,  40.953266 ,  38.892868 ,  55.221077 ,  37.24937  ,\n        54.081284 ,  48.51023  ,  90.473175 ,  90.25237  ,  63.059616 ,\n        55.496113 ,  45.88988  , 101.13147  ,  83.982445 ,  62.357014 ,\n        83.77875  ,  75.288635 ,  58.234425 ,  87.59431  ,  32.57698  ,\n        91.79604  ,  19.468853 ,  47.08475  ,  87.582855 ,  49.781307 ,\n        27.8644   ,  40.453773 ,  80.77259  , 104.03627  ,  55.66896  ,\n        62.26898  ,  65.54434  ,  54.508057 ,  50.90199  ,  86.50163  ,\n        50.98347  ,  70.88063  ,  23.03667  ,  24.737543 ,  39.238857 ,\n        42.344624 ,  57.84006  ,  37.87034  ,  72.647446 ,  69.31329  ,\n       106.028824 ,  45.494217 ,  86.37074  ,  64.89128  ,  86.20807  ,\n        53.53678  ,  95.40891  ,  38.040493 ,  49.87907  ,  64.12575  ,\n        29.608885 ,  39.23914  ,  57.670143 ,  58.414845 ,  83.49128  ,\n        63.99319  ,  53.60132  ,  39.354385 ,  28.63551  ,  78.86905  ,\n        51.595383 ,  58.08909  ,  80.69144  ,  23.418428 ,  57.054802 ,\n        75.293915 ,  33.081192 ,  64.75548  ,  41.322258 ,  61.338394 ,\n        80.06691  ,  36.96937  ,  70.88803  ,  25.568708 ,  47.28445  ,\n        93.53495  ,  34.65738  ,  41.77863  ,  92.86379  ,  36.714603 ,\n        51.996235 ,  67.98312  ,  35.560284 ,  46.312393 ,  45.01425  ,\n        54.374306 ,  97.19392  ,  39.091953 ,  91.10118  ,  63.324642 ,\n        96.52199  ,  60.473366 ,  60.804615 ,  46.19127  ,  59.351746 ,\n        39.998375 ,  31.039242 ,  18.593771 ,  52.945107 ,  60.6545   ,\n        45.968033 ,  14.129834 ,  36.25605  ,  68.50014  ,  77.7913   ,\n        32.09539  , 111.92507  ,  84.68035  ,  46.52082  ,  68.633804 ,\n        37.733894 ,  76.48987  ,  37.969753 ,  46.305683 ,  67.35023  ,\n        94.8595   ,  70.206894 ,  49.065796 ,  41.775654 ,  40.223568 ,\n        22.521826 ,  69.0937   ,  59.403687 ,  48.705494 ,  38.8448   ,\n        58.373756 ,  40.54574  ,  74.67735  ,  84.10521  ,  37.081413 ,\n        50.94915  ,  48.60359  ,  44.79557  ,  74.970566 ,  61.68171  ,\n        57.10968  ,  29.747301 ,  47.905746 ,  59.59996  , 103.89263  ,\n        90.96795  ,  55.178734 ,  89.638176 ,  53.846233 ,  40.664696 ,\n        31.449385 ,  23.3142   ,  35.27089  ,  76.74995  ,  57.63827  ,\n         7.867547 , 124.07718  ,  55.370304 ,  46.81393  ,  67.67152  ,\n        30.831724 ,  39.328278 , 142.8537   ,  74.52344  ,  30.59463  ,\n        43.134567 ,  74.18304  ,  42.656925 ,  25.392286 ,  14.868227 ,\n        53.048473 ,  53.105076 ,  39.85648  ,  58.08231  ,  73.28237  ,\n        44.88827  ,  35.170967 ,  36.435715 ,  46.718624 ,  63.56747  ,\n        52.097847 ,  55.791428 ,  28.518597 ,  66.86307  ,  58.865444 ,\n        40.53021  ,  58.561558 ,  57.531788 ,  71.44862  ,  11.669909 ,\n        63.002384 ,  93.68805  ,  76.414474 ,  50.15733  ,  50.267696 ,\n        82.53179  ,  26.114214 ,  45.79458  ,  67.34874  ,  66.27401  ,\n        34.994728 ,  18.218319 ,  96.48739  ,  43.16696  ,  45.82847  ,\n        84.07925  ,  43.103317 ,  90.47642  ,  84.237465 ,  92.81969  ,\n        25.887617 ,  43.557446 ,  83.36187  ,  24.335184 ,  72.365974 ,\n        36.909428 ,  60.24494  ,  67.602036 ,  79.88512  ,  62.49799  ,\n        20.303186 ,  51.502735 ,  59.512787 ,  38.527134 ,  66.37044  ,\n        36.605347 ,  59.929134 ,  55.127434 ,  36.31103  , 110.27735  ,\n        53.296047 ,  71.18892  ,  44.51504  ,  59.87354  ,  39.661606 ,\n        26.164122 , 118.796875 ,  45.002445 , 130.94402  , 124.71796  ,\n        79.58918  ,  48.93841  ,  37.741608 , 105.87785  ,  60.387787 ,\n        62.088326 ,  98.529854 , 115.65272  ,  68.66532  ,  45.198914 ,\n        98.86693  ,  73.71775  ,  45.95691  ,  88.58099  ,  67.76242  ,\n        78.426674 ,  73.363716 ,  37.21157  ,  56.132843 ,  77.150925 ,\n        32.39462  ,  36.375248 ,  48.270706 ,  77.64129  ,  29.090282 ,\n        20.468647 ,  28.896572 ,  90.681725 ,  42.997383 ,  41.12312  ,\n        76.55418  ,  86.02553  ,  52.883064 , 100.122185 ,  38.012802 ,\n        54.199413 ,  15.784885 ,  90.87215  ,  31.733513 ,  33.19848  ,\n       131.68094  ,  71.97969  ,  57.959503 ,  54.48252  ,  66.43561  ,\n        42.625973 ,  48.704716 ,  81.509895 ,  95.36916  ,  65.895355 ,\n        97.74641  ,  73.36047  ,  77.99884  ,  81.37606  ,  22.779171 ,\n        55.537884 ,  90.02999  ,  46.33885  ,  63.908543 ,  96.16487  ,\n        36.035072 ,  42.207912 ,  97.556625 ,  33.997826 ,  45.52863  ,\n        13.198205 ,  57.83864  ,  49.157917 ,  77.663704 ,  23.948753 ,\n        56.25514  ,  32.718655 ,  37.609158 ,  97.961914 ,  14.878919 ,\n        42.085896 ,  68.57295  ,  93.68606  , 117.25308  ,  64.402824 ,\n        66.31641  ,  66.173294 ,  62.216824 ,  66.140625 ,  36.018005 ,\n        38.27104  ,  56.582253 ,  60.38856  ,  41.765232 ,  59.011444 ,\n        40.504498 ,  34.606884 ,  69.48138  ,  76.70254  ,  59.759583 ,\n        95.94884  ,  80.09551  ,  70.74434  , 110.78885  ,  85.30709  ,\n        60.779926 ,  29.483873 ,  74.15569  , 108.997154 ,  65.77962  ,\n        68.187935 ,  51.5655   , 103.7763   ,  71.56532  ,  74.74839  ,\n        43.204536 ,  74.33128  ,  79.62722  ,  56.87739  ,  80.60042  ,\n        50.58737  ,  20.706589 ,  51.317135 ,  78.34739  ,  77.34564  ,\n        73.56615  ,  42.696022 ,  32.346973 ,  52.21535  ,  42.45907  ,\n        34.110035 , 111.11132  ,  98.6665   ,  50.124115 ,  51.180996 ,\n        73.98799  ,  59.609566 ,  28.971537 ,  43.945236 ,  37.531155 ,\n        69.73972  ,  97.31396  ,  65.96316  ,  26.065304 ,  22.99353  ,\n        74.01848  ,  43.6303   ,  39.24514  ,  82.66685  ,  41.54878  ,\n        82.83558  ,  34.715126 ,  85.04845  ,  75.168884 ,  81.09073  ,\n        34.347042 ,  65.79762  ,  61.535244 ,  44.87879  ,  62.877037 ,\n        68.15986  ,  49.494114 ,  43.728527 ,  35.953224 ,   6.3217554,\n        26.634302 ,  50.87236  ,  48.43004  ,  59.66461  ,  76.51845  ,\n        50.900276 ,  78.248764 ,  34.95333  ,  86.968666 ,  52.151142 ,\n        69.30283  ,  88.40111  , 114.795586 ,  43.78263  ,  44.53131  ,\n       129.01378  ,  43.246784 ,  71.338554 ,  57.042305 ,  43.24414  ,\n        57.355972 ,  70.13343  ,  34.371548 ,  60.926956 ,  77.55454  ,\n        42.169044 ,  11.314539 , 125.64181  ,  80.80233  ,  37.313137 ,\n        65.62961  ,  69.26098  ,  86.302925 ,  36.354435 ,  44.15472  ,\n        34.012074 ,  50.091248 ,  63.655735 ,  70.6508   ,  43.236908 ,\n        36.410206 , 109.3494   ,  35.932476 , 103.90722  ,  59.898315 ,\n        68.33765  ,  27.816925 ,  47.492214 ,  62.240513 ,  74.55919  ,\n        65.35408  ,  44.108315 ,  45.660725 ,  50.635883 ,  48.42626  ,\n        62.685318 ,  85.65201  ,  52.055862 ,  64.67885  ,  68.94939  ,\n        61.340065 ,  27.176786 ,  30.370754 ,  26.00624  ,  18.402826 ,\n        67.95624  ,  89.55775  ,  35.380024 ,  38.62779  , 124.564445 ,\n        21.223116 ,  21.203836 ,  76.02082  ,  98.763214 ,  65.53459  ,\n        40.44594  ,  47.261703 ,  87.44083  ,  63.66831  ,  76.14912  ,\n        85.636215 ,  38.53352  ,  48.104168 ,  52.744843 ,  42.61375  ,\n        35.276066 ,  27.889524 ,  46.442226 ,  71.941956 ,  15.515389 ,\n        74.18914  ,  95.8095   ,  47.280388 ,  83.02086  ,  52.597786 ,\n       103.497444 ,  40.249496 ,  71.38927  ,  47.335117 ,  17.200737 ,\n        51.944817 ,  52.318844 ,  72.62752  ,  59.803116 ,  50.60217  ,\n        28.69281  ,  48.688976 ,  47.327454 ,  71.59802  ,  53.250916 ,\n        92.892075 ,  36.877773 , 100.97064  ,  71.79717  ,  43.28547  ,\n        77.52812  ,  37.373856 ,  26.117876 ,  51.768173 ,  71.255035 ,\n        61.80762  ,  32.37222  ,  34.800648 ,  80.992676 ,  53.883842 ,\n        51.975037 , 114.079    ,  51.83038  ,  29.199032 ,  44.289852 ,\n        35.415962 ,  44.266666 ,  34.715504 ,  66.485954 ,  64.789276 ,\n        63.55486  ,  46.43287  ,  24.270092 ,  62.415665 ,  47.66812  ,\n        44.44628  ,  67.50604  ,  45.18284  ,  36.588448 ,  51.571457 ,\n        57.630688 ,  52.716717 ,  38.74723  ,  97.81949  ,  85.080666 ,\n        71.7339   ,  54.91753  ,  33.422394 ,  78.16631  ,  42.8263   ,\n        36.04406  ,  30.241848 ,  40.79693  ,  55.92587  ,  52.772514 ,\n        26.511503 ,  35.22015  ,  61.73416  ,  61.153763 ,  44.752197 ,\n         7.0845323,  64.37122  ,  90.16733  ,  79.88007  ,  67.44517  ,\n        31.027992 ,  57.35526  ,  84.325516 ,  63.96603  ,  50.415077 ,\n        86.92932  ,  54.88164  ,  53.114155 , 103.697296 ,  74.77197  ,\n        51.948017 ,  58.89019  ,  62.683887 ,  89.47956  ,  70.81908  ,\n        65.18542  , 148.64937  ,  72.51663  ,  36.891304 ,  42.281643 ,\n        94.81697  ,  69.93334  ,  53.528904 ,  70.36759  ,  99.11354  ,\n        51.40643  ,  29.166882 ,  42.00134  ,  44.60013  ,  73.24831  ,\n        28.139803 ,  24.11077  ,  12.255024 ,  57.277393 ,  39.415916 ,\n        60.8919   ,  14.306446 ,  30.319149 ,  16.146294 ,  91.095085 ,\n        86.36181  ,  50.41704  , 100.04363  ,  43.313007 ,  86.01434  ,\n        61.90518  ,  40.645878 ,  22.959755 ,  64.4086   ,  75.43725  ,\n        65.911285 ,  78.96931  ,  41.744614 ,  31.437647 ,  88.69909  ,\n        45.983253 ,  68.49299  ,  47.407192 ,  35.460693 ,  86.245636 ,\n        18.36505  ,  44.868565 ,  91.90877  ,  38.7004   ,  58.217632 ,\n        60.85589  ,  71.02861  ,  62.764103 ,  55.335033 , 137.2412   ,\n        32.86756  ,  96.307335 ,  63.024475 ,  40.78706  ,  30.598013 ,\n        52.922222 ,  50.51151  ,  68.00105  ,  53.503544 ,  76.13032  ,\n        64.69219  ,  35.939407 ,  51.485897 ,  51.036537 ,  90.88915  ,\n        41.308006 ,  30.155441 ,  17.71377  ,  34.946857 ,  59.048565 ,\n        42.01811  ,  53.088722 ,  60.084538 ,  69.84447  ,  86.661125 ,\n        63.79037  ,  94.20771  ,  54.119793 ,  61.73174  ,  54.939655 ,\n        70.063225 ,  35.501083 , 140.62042  ,  11.754612 ,  32.06818  ,\n        49.47347  ,  86.92959  ,  44.48659  ,  86.30449  ,  44.740818 ,\n        85.65537  ,  42.122707 ,  57.946922 ,  27.217972 ,  46.943348 ,\n         2.8935587,  50.440525 ,  59.981888 ,  69.288055 ,  34.06078  ,\n        45.510807 ,  76.99098  ,  54.73999  ,  39.59969  ,  69.52559  ,\n        42.53596  ,  39.597816 ,  22.154795 , 111.20289  ,  19.114378 ,\n        61.71545  ,  32.23421  ,  21.671143 ,  62.01383  ,  20.417807 ,\n        80.42085  ,  40.832035 ,  28.56502  ,  45.759655 ,  93.07695  ,\n        84.81642  ,  86.180374 ,  67.67204  ,  64.1038   ,  96.09124  ,\n        11.590811 ,  56.245155 ,  87.31691  ,  95.71402  ,  40.66828  ],\n      dtype=float32)"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.9997262737476746\n",
      "Testing score: 0.8700104324538045\n"
     ]
    }
   ],
   "source": [
    "print(f'Testing score: {model.score(X_train, y_train)}')\n",
    "print(f'Testing score: {model.score(X_test, y_test)}')\n",
    "print(r2_score(y_test, model.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "\n",
    "# Column List for cat\n",
    "cols = list(full_pipeline.transformer_list[0][1][1].cat_columns) + list(full_pipeline.transformer_list[1][1][1].num_columns)\n",
    "\n",
    "dt = pd.DataFrame(data=model.steps[1][1].feature_importances_).transpose()\n",
    "dt.columns = cols\n",
    "dt.transpose().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "# Adding Gridsearch CV to the model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def train_estimator(estimator):\n",
    "    best_estimators = {}\n",
    "    for clf, params in tqdm(estimator.items()):\n",
    "        model_svr = Pipeline(steps=[('preprocessor', full_pipeline),\n",
    "                                    ('clf', clf)])\n",
    "        gsc = GridSearchCV(\n",
    "                estimator= model_svr,\n",
    "                param_grid=params,\n",
    "                cv=5, scoring='r2', verbose=0, n_jobs=-1)\n",
    "\n",
    "        gsc.fit(X_train, y_train)\n",
    "        # best params and model\n",
    "        gsc.best_params_\n",
    "        best_estimator = gsc.best_estimator_\n",
    "        best_estimators[clf] = best_estimator.named_steps['clf']\n",
    "    return gsc, best_estimators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "regressors = {SVR(): {\n",
    "                'clf__C': [0.1, 1, 100, 1000],\n",
    "                'clf__epsilon': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "                'clf__gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n",
    "            },\n",
    "            XGBRegressor():{\n",
    "\n",
    "\n",
    "            }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.73s/it]\n"
     ]
    }
   ],
   "source": [
    "gsc, estimators = train_estimator(regressors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "0.902513103205044"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now Hyperopt as Hypertuning technique"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc Mean:                                             \n",
      "-1.0950942332364322                                   \n",
      "Acc Mean:                                                                       \n",
      "0.6795604853849365                                                              \n",
      "Acc Mean:                                                                       \n",
      "0.8522925059535901                                                              \n",
      "Acc Mean:                                                                        \n",
      "0.6932066399525834                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.8624648038567365                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.8422554751570047                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.5596683509554039                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.7737203862673669                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.7631406345313445                                                               \n",
      "Acc Mean:                                                                        \n",
      "0.8492770994784011                                                               \n",
      "Acc Mean:                                                                         \n",
      "0.8230351464365476                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8044006675098059                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.7954846938769551                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.4963618502251951                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.6341076005734576                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.6794666453620735                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8338770701231006                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8174137260758474                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.38040059397461723                                                               \n",
      "Acc Mean:                                                                         \n",
      "-1.2787745651573073                                                               \n",
      "Acc Mean:                                                                         \n",
      "0.7755836926823286                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8770545641732376                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8687061035792111                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8752267905530294                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8731719063954373                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.873318533497239                                                                 \n",
      "Acc Mean:                                                                         \n",
      "0.8788098953991961                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8556402789970896                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.6817700421350391                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8273984633399412                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.5675212670304078                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8696134484122048                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.873254269176558                                                                 \n",
      "Acc Mean:                                                                         \n",
      "0.8224293033180119                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8430701884198941                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8271084529471111                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.19367859371002183                                                               \n",
      "Acc Mean:                                                                         \n",
      "0.8446814693766436                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.11622929633982712                                                               \n",
      "Acc Mean:                                                                         \n",
      "0.8410037734309392                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8578602045755082                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.7661409179900525                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.866261021291456                                                                 \n",
      "Acc Mean:                                                                         \n",
      "0.8609609903371428                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.6921802042287102                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8476886267835507                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8348487313787606                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.8569871920340573                                                                \n",
      "Acc Mean:                                                                         \n",
      "0.766268141720964                                                                 \n",
      "Acc Mean:                                                                         \n",
      "0.8465281676764652                                                                \n",
      "100%|██████████| 50/50 [00:44<00:00,  1.12trial/s, best loss: 0.12119010460080393]\n",
      "Best:  {'colsample_bytree': 0.9500000000000001, 'gamma': 0.23, 'learning_rate': 0.06, 'max_depth': 19, 'min_child_weight': 9.0, 'n_estimators': 17, 'subsample': 0.71}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin\n",
    "import xgboost as xgb\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    regressor = xgb.XGBRegressor(n_estimators = space['n_estimators'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            learning_rate = space['learning_rate'],\n",
    "                            gamma = space['gamma'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree = space['colsample_bytree']\n",
    "                            )\n",
    "\n",
    "    # hyper_pipe = Pipeline(steps=[('preprocessor', full_pipeline),\n",
    "    #                              {'regressor', regressor}])\n",
    "\n",
    "    regressor.fit(full_pipeline.fit_transform(X_train,y_train),y_train.to_numpy())\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = regressor, X = full_pipeline.fit_transform(X_train,y_train),\n",
    "                                 y = y_train.to_numpy(), cv = 10, scoring='r2')\n",
    "    CrossLoss = accuracies.mean()\n",
    "    print(\"Acc Mean:\", CrossLoss)\n",
    "\n",
    "    return{'loss':1 - CrossLoss, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'n_estimators' : hp.choice('n_estimators', range(20, 205, 5)),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.9500000000000001,\n             gamma=0.23, gpu_id=-1, importance_type='gain',\n             interaction_constraints='', learning_rate=0.06, max_delta_step=0,\n             max_depth=19, min_child_weight=9.0, missing=nan,\n             monotone_constraints='()', n_estimators=17, n_jobs=6,\n             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n             scale_pos_weight=1, subsample=0.71, tree_method='exact',\n             validate_parameters=1, verbosity=None)"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "regressors = XGBRegressor(n_estimators = best['n_estimators'],\n",
    "                            max_depth = best['max_depth'],\n",
    "                            learning_rate = best['learning_rate'],\n",
    "                            gamma = best['gamma'],\n",
    "                            min_child_weight = best['min_child_weight'],\n",
    "                            subsample = best['subsample'],\n",
    "                            colsample_bytree = best['colsample_bytree']\n",
    "                            )\n",
    "\n",
    "regressors.fit(full_pipeline.fit_transform(X_train,y_train), y_train.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CrossValMean:  -0.16562951841904971\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = regressors, X = full_pipeline.fit_transform(X_train,y_train), y = y_train.to_numpy(), cv = 10,\n",
    "                             scoring='r2')\n",
    "CrossValMean = accuracies.mean()\n",
    "print(\"Final CrossValMean: \", CrossValMean)\n",
    "\n",
    "CrossValSTD = accuracies.std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressors.predict(full_pipeline.transform(X_test))\n",
    "y_pred = pd.DataFrame(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.054377073622303485"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}